{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.utils import Sequence, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'datasets\\\\CASIA-PalmprintV1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-872a6691f83c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtrain_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train files: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Eval files: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-872a6691f83c>\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGES_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0meval_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'datasets\\\\CASIA-PalmprintV1'"
     ]
    }
   ],
   "source": [
    "IMAGES_DIR = os.path.join(\"..\", \"datasets\", \"CASIA-PalmprintV1\")\n",
    "num_classes = 300\n",
    "\n",
    "def train_test_split():\n",
    "    labels = sorted(os.listdir(IMAGES_DIR))[:num_classes]\n",
    "    train_files = []\n",
    "    eval_files = []\n",
    "    for label in labels:\n",
    "        folder = os.path.join(IMAGES_DIR, label)\n",
    "        files = [os.path.join(folder, file) for file in os.listdir(folder) if file.endswith(\".jpg\")]\n",
    "        shuffle(files)\n",
    "        split_idx = int(len(files) * 0.7)\n",
    "        train_files.extend(files[:split_idx])\n",
    "        eval_files.extend(files[split_idx:])\n",
    "    return train_files, eval_files, labels\n",
    "\n",
    "train_files, eval_files, labels = train_test_split()\n",
    "print(\"Train files: {}\".format(len(train_files)))\n",
    "print(\"Eval files: {}\".format(len(eval_files)))\n",
    "print(\"Labels: {}\".format(len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_by_filename = {}\n",
    "files = train_files + eval_files\n",
    "for file in tqdm(files):\n",
    "    image = cv2.imread(file)\n",
    "    image = cv2.resize(image, (224, 224)).astype(np.float32)\n",
    "    image /= 255.\n",
    "    image_by_filename[file] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonIDSequence(Sequence):\n",
    "\n",
    "    def __init__(self, files, labels, batch_size, extract_palm=False):\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "        shuffle(self.files)\n",
    "        self.num_labels = len(self.labels)\n",
    "        self.batch_size = batch_size\n",
    "        self.extract_palm = extract_palm\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.files) / self.batch_size)\n",
    "\n",
    "    def load_palm_print(self, image_file):\n",
    "        if INPUT_SHAPE[2] == 1:\n",
    "            image = cv2.imread(image_file, 0)\n",
    "        else:\n",
    "            image = cv2.imread(image_file)\n",
    "        if self.extract_palm:\n",
    "            image = extract_palm_from_img(image)\n",
    "        try:\n",
    "            image = cv2.resize(image, INPUT_SHAPE[:2])\n",
    "        except:\n",
    "            print(\"image_file:\", image_file)\n",
    "        image = image * 1./255\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.files[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        y = [os.path.basename(os.path.dirname(file)) for file in X ]\n",
    "        palm_prints = np.array([image_by_filename[image] for image in X])\n",
    "        y_indices = [to_categorical(self.labels.index(i), num_classes=self.num_labels)\n",
    "                     for i in y]\n",
    "        return palm_prints, np.array(y_indices)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        shuffle(self.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-754328bed6f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpalm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m# model.summary()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-754328bed6f6>\u001b[0m in \u001b[0;36mpalm_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m# Dropout layer to reduce overfitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"last_dense\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m                                \u001b[1;31m# Softmax for multiclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "def palm_model():\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    x = vgg16.output\n",
    "    x = layers.Flatten()(x)                                # Flatten dimensions to for use in FC layers\n",
    "    x = layers.Dense(4096, activation='relu')(x)\n",
    "    x = layers.Dense(4096, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)                             # Dropout layer to reduce overfitting\n",
    "    x = layers.Dense(len(labels), name=\"last_dense\")(x) \n",
    "    x = layers.Softmax()(x)                                # Softmax for multiclass\n",
    "    return Model(inputs=vgg16.input, outputs=x)\n",
    "\n",
    "model = palm_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PersonIDSequence(train_files, labels, batch_size=64)\n",
    "eval_ds = PersonIDSequence(eval_files, labels, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 56 steps, validate for 26 steps\n",
      "Epoch 1/10\n",
      "56/56 [==============================] - 25s 442ms/step - loss: 0.8877 - accuracy: 0.8278 - val_loss: 0.9152 - val_accuracy: 0.8384\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 24s 425ms/step - loss: 0.4673 - accuracy: 0.9238 - val_loss: 0.6472 - val_accuracy: 0.8824\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 24s 432ms/step - loss: 0.2889 - accuracy: 0.9612 - val_loss: 0.4845 - val_accuracy: 0.9158\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 25s 445ms/step - loss: 0.1904 - accuracy: 0.9780 - val_loss: 0.4078 - val_accuracy: 0.9189\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 26s 457ms/step - loss: 0.1290 - accuracy: 0.9883 - val_loss: 0.3513 - val_accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 26s 458ms/step - loss: 0.0877 - accuracy: 0.9944 - val_loss: 0.2816 - val_accuracy: 0.9430\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 26s 461ms/step - loss: 0.0602 - accuracy: 0.9983 - val_loss: 0.2483 - val_accuracy: 0.9474\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 26s 467ms/step - loss: 0.0435 - accuracy: 0.9989 - val_loss: 0.2226 - val_accuracy: 0.9529\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 26s 465ms/step - loss: 0.0372 - accuracy: 0.9972 - val_loss: 0.2229 - val_accuracy: 0.9560\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 26s 467ms/step - loss: 0.0303 - accuracy: 0.9994 - val_loss: 0.1912 - val_accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.0001\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(lr))\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 7s 265ms/step - loss: 0.1912 - accuracy: 0.9610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19115729486713043, 0.9609907]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"palm_model_e{}_lr{}.h5\".format(epochs, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
